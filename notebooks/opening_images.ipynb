{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d6c7fd-6e82-4385-b5f7-b0378ac1aef8",
   "metadata": {},
   "source": [
    "# Opening images\n",
    "\n",
    "This notebook will show you how to access metadata and pixel values of images with QuBaLab.\n",
    "\n",
    "A few classes and functions of the QuBaLab package will be presented in this notebook. To view more details on them, you can go to the documentation at https://qupath.github.io/qubalab-docs/ and type a class/function name in the search bar. You will then see details on the arguments that functions accept.\n",
    "\n",
    "QuBaLab uses the `ImageServer` class to open an image and get its metadata and pixel values. `ImageServer` is an abstract class, so it cannot be directly created. Instead, you have to choose an implementation based on the type of image you want to open:\n",
    "\n",
    "* If you need to open an RGB pyramidal image, you can use an `OpenSlideServer`. This class internally uses [OpenSlide](https://openslide.org/): it can read all resolutions of a large pyramidal image but is only suitable for RGB images.\n",
    "* If you need to open any kind of microscopy image, you can use an `BioIOServer`. This class internally uses [BioIO](https://github.com/bioio-devs/bioio) which is suited for a lot of formats. However, this library does not properly support pyramids, so you might only get the full resolution image when opening a pyramidal image.\n",
    "* If your image has an embedded ICC profile, or if you want to apply a custom ICC Profile to an image, you can use an `IccProfileServer`. This takes another `ImageServer` as a parameter and changes pixels values based on the transforms defined in the ICC profile. You can find more information about ICC profiles on [this link](http://www.andrewjanowczyk.com/application-of-icc-profiles-to-digital-pathology-images/).\n",
    "* If you want to represent objects such as annotations or detections on an image, you can use a `LabeledImageServer`. Pixel values are labels corresponding to image features (such as annotations) present on an image. See the *working_with_objects.ipynb* notebook for more information.\n",
    "* If you want to access an image opened in QuPath, you can use a `QuPathServer`. See the *communicating_with_qupath.ipynb* notebook for more information.\n",
    "\n",
    "All these `ImageServer` are used in the same way, only their creation differ. This notebook will show how to create and use these servers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5756f-d27e-4720-bbcd-f430b7562351",
   "metadata": {},
   "source": [
    "## ImageServer creation\n",
    "\n",
    "To create an `ImageServer`, you have to use one of the implementations presented above.\n",
    "\n",
    "This notebook will download several large sample images. You can change the line below to define a folder where images will be stored once downloaded (or leave it blank not to use any cache)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df86bfe0-aaf6-4764-817d-417584e1720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_folder = \"\"   # define a folder where images will be stored. Leave blank to not use any cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9aefa-8be1-41a3-ac0b-88c2cd76e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a utility function to find or download an image\n",
    "\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import tempfile\n",
    "\n",
    "if cache_folder != \"\":\n",
    "    Path(cache_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_image(image_name, image_url):\n",
    "    if cache_folder == \"\":\n",
    "        filename = tempfile.gettempdir() / Path(image_name)\n",
    "    else:\n",
    "        filename = Path(cache_folder) / image_name\n",
    "    \n",
    "    if filename is None or not(filename.exists()):\n",
    "        print(f\"Downloading {image_name}...\")\n",
    "        path, _ = urllib.request.urlretrieve(image_url, filename=filename)\n",
    "        print(f'{image_name} saved to {path}')\n",
    "    else:\n",
    "        path = filename\n",
    "        print(f'{image_name} found in {path}')\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b6e21-af40-41ad-accf-0e64c2f96188",
   "metadata": {},
   "source": [
    "### OpenSlideServer\n",
    "\n",
    "We will use the **CMU-1.svs** image (CC0 1.0 license) because it's a pyramidal RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9ae0f-e303-43c4-bc9d-9230fa4e9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download or get image\n",
    "cmu_path = get_image(\"CMU-1.svs\", \"https://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/CMU-1.svs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de32af2-7005-4f91-880f-876240e8772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubalab.images.openslide_server import OpenSlideServer\n",
    "\n",
    "\n",
    "# Create the ImageServer from the image path. This will read the image metadata but not the pixel values yet.\n",
    "# This function has optional parameters you can find in the documentation\n",
    "openslide_server = OpenSlideServer(cmu_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f004b-9383-4053-921e-d8d691749b00",
   "metadata": {},
   "source": [
    "### BioIOServer\n",
    "\n",
    "We will use the **Patient_test_1.ome.tiff** image (CC0 license) because it's a relatively small fluorescence image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf9f0d5-52c0-4d0f-9ee5-27835a8b638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download or get image\n",
    "fluoro_path = get_image(\"Patient_test_1.ome.tiff\", \"https://ftp.ebi.ac.uk/biostudies/fire/S-BIAD/463/S-BIAD463/Files/my_submission/Validation_raw/DCIS/Patient_test_1.ome.tiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a21e2f-c19e-4348-9b05-1adb8f443b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubalab.images.bioio_server import BioIOServer\n",
    "\n",
    "\n",
    "# Create the ImageServer from the image path. This will read the image metadata but not the pixel values yet.\n",
    "# This function has optional parameters you can find in the documentation\n",
    "bioio_server = BioIOServer(fluoro_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6341ec-49f7-46a5-81af-80693557029e",
   "metadata": {},
   "source": [
    "### IccProfileServer\n",
    "\n",
    "An `IccProfileServer` needs an existing `ImageServer`. We will use the `OpenSlideServer` created above, because it represents the **CMU-1.svs** image, and SVS images usually embed an ICC profile. However, any `ImageServer` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53de4e0-b146-4a07-8617-2a16aaaeea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubalab.images.icc_profile_server import IccProfileServer\n",
    "\n",
    "# Create the IccProfileServer from the existing OpenslideServer. The two servers will have the same metadata, but pixel values might differ a bit\n",
    "icc_profile_server = IccProfileServer(openslide_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78e137-9ee3-4330-9867-b79db40b6018",
   "metadata": {},
   "source": [
    "### LabeledImageServer\n",
    "\n",
    "A `LabeledImageServer` represents objects such as annotations or detections on an image. It needs the metadata of an image and some objects.\n",
    "\n",
    "We will not detail the creation of this server here. Take a look at the *working_with_objects.ipynb* notebook for more information. However, all functions presented below are also valid for a `LabeledImageServer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bb4498-1d6b-45ec-b80c-d3bf67900acf",
   "metadata": {},
   "source": [
    "### QuPathServer\n",
    "\n",
    "A `QuPathServer` allows you to read an image opened in QuPath\n",
    "\n",
    "We will not detail the creation of this server here. Take a look at the *communicating_with_qupath.ipynb* notebook for more information. However, all functions presented below are also valid for a `QuPathServer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a79f3-9467-4a52-ad80-82e74721c9cc",
   "metadata": {},
   "source": [
    "## ImageServer usage\n",
    "\n",
    "To access metadata and pixel values from an `ImageServer`, you can use the functions presented below.\n",
    "\n",
    "These functions are available for any implementation of `ImageServer`. We will use the `OpenSlideServer` created above but they are also valid for any other `ImageServer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a85fd8-7135-4cba-a499-49ce74c7c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = openslide_server  # you can change it to bioio_server or icc_profile_server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3737dc9-c92b-4721-8dfa-191d1b34eaa6",
   "metadata": {},
   "source": [
    "### Image metadata\n",
    "\n",
    "Image metadata is accessed with the `ImageServer.metadata` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb53865-26a9-4041-9123-07126efc2285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access image metadata\n",
    "\n",
    "metadata = server.metadata\n",
    "\n",
    "print(f'Image path: {metadata.path}')\n",
    "print(f'Image name: {metadata.name}')\n",
    "print()\n",
    "\n",
    "print('Levels:')\n",
    "for level, shape in enumerate(metadata.shapes):\n",
    "    print(f'Shape of level {level}: {shape}')\n",
    "print()\n",
    "\n",
    "print('Pixel calibration:')\n",
    "print(f'Pixel length on x-axis: {metadata.pixel_calibration.length_x}')\n",
    "print(f'Pixel length on y-axis: {metadata.pixel_calibration.length_y}')\n",
    "print()\n",
    "\n",
    "print(f'Pixel type: {metadata.dtype}')\n",
    "print()\n",
    "\n",
    "print(f'Downsamples: {metadata.downsamples}')\n",
    "print()\n",
    "\n",
    "print('Channels:')\n",
    "for channel in metadata.channels:\n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901d89f-1ebf-48cd-aeec-16e85f73d039",
   "metadata": {},
   "source": [
    "### Pixel values\n",
    "\n",
    "Pixel values can be retrieved in two different ways:\n",
    "\n",
    "* If the image is small enough to fit in memory, or if only one tile of the image should be read, then the `ImageServer.read_region()` function can be used.\n",
    "* Otherwise, the `ImageServer.level_to_dask()` or `ImageServer.to_dask()` functions can be used. They will return a [Dask array](https://docs.dask.org/en/latest/array.html) which gives as a NumPy-like way to access the pixels without fitting all pixel values into memory. Indeed, as long as `compute()` is not called on the Dask array, the pixel values won't be read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1274cbc-1775-4af7-8472-32a9fc06c07d",
   "metadata": {},
   "source": [
    "#### read_region()\n",
    "\n",
    "`ImageServer.read_region()` returns a NumPy array of a tile of the image with dimensions `(number_of_channels, tile_height, tile_width)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13e263f-6a0f-4c1a-b2e0-2be21fa9200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and show lowest resolution image with read_region\n",
    "\n",
    "highest_downsample = server.metadata.downsamples[-1]\n",
    "lowest_resolution = server.read_region(highest_downsample)\n",
    "\n",
    "print(f'Image shape: {lowest_resolution.shape}')\n",
    "\n",
    "# This calls a utility function from qubalab to plot the image\n",
    "# If the image is RGB, the entire image is plotted\n",
    "# Otherwise, only the first channel is plotted\n",
    "from qubalab.display.plot import plotImage\n",
    "import matplotlib.pyplot as plt\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, lowest_resolution)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bec8ea3-8b0e-445e-9eab-3471d5d8ad5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and show tile of full resolution image with read_region\n",
    "\n",
    "# Read a 2000x1000 pixels tile whose top left pixel is located at x=13000 and y=15000 on the full resolution image\n",
    "# You'll have to change these values if you want to open a smaller image\n",
    "downsample = 1\n",
    "x = 13000\n",
    "y = 15000\n",
    "width = 2000\n",
    "height = 1000\n",
    "tile = server.read_region(downsample, x=x, y=y, width=width, height=height)\n",
    "\n",
    "print(f'Tile shape: {tile.shape}')\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941ea36-9757-4e69-9373-5405c60e45c0",
   "metadata": {},
   "source": [
    "#### level_to_dask()\n",
    "\n",
    "`ImageServer.level_to_dask()` returns a Dask array representing a single resolution of the image.\n",
    "\n",
    "Pixels of the returned array can be accessed with the following order: (t, c, z, y, x). There may be less dimensions for simple images: for example, an image with a single timepoint and a single z-slice will return an array of dimensions (c, y, x) (which is the case here). However, there will always be dimensions x and y, even if they have a size of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376bd6be-560b-487e-9b8f-0df96107bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and show lowest resolution image with level_to_dask\n",
    "\n",
    "last_level = server.metadata.n_resolutions - 1\n",
    "lowest_resolution = server.level_to_dask(last_level)\n",
    "\n",
    "# Pixel values are not read yet, but you can get the shape of the image\n",
    "print(f'Image shape: {lowest_resolution.shape}')\n",
    "\n",
    "# Compute array. This will read the pixel values\n",
    "lowest_resolution = lowest_resolution.compute()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, lowest_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ac4af7-9280-4b9d-b0ff-dfbb979a17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and show tile of full resolution image with level_to_dask\n",
    "\n",
    "first_level = 0\n",
    "highest_resolution = server.level_to_dask(first_level)\n",
    "\n",
    "print(f'Full resolution image shape: {highest_resolution.shape}')\n",
    "\n",
    "# Only read a 2000x1000 pixels tile whose top left pixel is located at x=13000 and y=15000 on the full resolution image\n",
    "x = 13000\n",
    "y = 15000\n",
    "width = 2000\n",
    "height = 1000\n",
    "tile = highest_resolution[:, y:y+height, x:x+width]\n",
    "\n",
    "print(f'Tile shape: {tile.shape}')\n",
    "\n",
    "# Compute array. This will only read the pixel values of the tile, not the entire image\n",
    "tile = tile.compute()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9931e730-4482-4a49-9a93-6eeb0060092a",
   "metadata": {},
   "source": [
    "#### to_dask()\n",
    "\n",
    "`ImageServer.to_dask()` returns a Dask array representing the image at any arbitrary downsample (even a downsample not stored in the image).\n",
    "\n",
    "Pixels of the returned array can be accessed with the following order: (t, c, z, y, x). There may be less dimensions for simple images: for example, an image with a single timepoint and a single z-slice will return an array of dimensions (c, y, x) (which is the case here). However, there will always be dimensions x and y, even if they have a size of 1.\n",
    "\n",
    "**Important!**\n",
    "> It turns out that requesting at an arbitrary downsample level is very slow - currently, all pixels are requested upon first compute (even for a small region), and then resized. Prefer using `ImageServer.level_to_dask()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd68d287-95e4-44e4-87b4-cdd408c4dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and show a tile of the image at an arbitray downsample\n",
    "\n",
    "downsample = 1.5\n",
    "image = server.to_dask(downsample)\n",
    "\n",
    "# Pixel values are not read yet, but you can get the shape of the image\n",
    "print(f'Image shape at downsample {downsample}: {image.shape}')\n",
    "\n",
    "# Only read a 2000x1000 pixels tile whose top left pixel is located at x=13000 and y=15000 on the downsampled image\n",
    "x = 13000\n",
    "y = 15000\n",
    "width = 2000\n",
    "height = 1000\n",
    "tile = image[:, y:y+height, x:x+width]\n",
    "\n",
    "print(f'Tile shape: {tile.shape}')\n",
    "\n",
    "# Compute array. This will only read the pixel values of the tile, not the entire image\n",
    "# This can take some time as explained above\n",
    "tile = tile.compute()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db947ab0-a073-4972-870a-ec28e29c2941",
   "metadata": {},
   "source": [
    "When you have a Dask Array, you can visualize the image using [napari](https://napari.org).\n",
    "\n",
    "napari is not installed by default on this project. You'll have to manually add it. You can then run this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e67ba-ede4-477d-b6fd-a8f3c76f27c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "import napari\n",
    "import dask.array as da\n",
    "\n",
    "level = 0\n",
    "image = server.level_to_dask(level)\n",
    "\n",
    "# image has resolutions (c, y, x) while napari accepts\n",
    "# resolutions (y, x, c), so they need to be reordered\n",
    "image = da.moveaxis(image, [0], [2])\n",
    "\n",
    "napari.view_image(image)\n",
    "napari.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
