{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a4f046e-a6e0-491f-8ff8-df88208c60de",
   "metadata": {},
   "source": [
    "# Working with objects\n",
    "\n",
    "This notebook will show how to exchange objects (e.g. annotations, detections) between QuPath and Python.\n",
    "\n",
    "As we will communicate with QuPath, it is recommended to go through the *communicating_with_qupath.ipynb* notebook first.\n",
    "\n",
    "Before running this notebook, you should launch QuPath, start the Py4J gateway, and open an image that has a few annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57058266-2e94-49eb-9d7d-34e06ab0ad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gateway created\n"
     ]
    }
   ],
   "source": [
    "from qubalab.qupath import qupath_gateway\n",
    "\n",
    "token = None   # change the value of this variable if you provided a token while creating the QuPath gateway\n",
    "port = 25333   # change the value of this variable if you provided a different port while creating the QuPath gateway\n",
    "gateway = qupath_gateway.create_gateway(auth_token=token, port=port)\n",
    "\n",
    "print(\"Gateway created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc856f-9bec-4a1a-ba7c-bb4dd07ab0f1",
   "metadata": {},
   "source": [
    "## Get objects from QuPath\n",
    "\n",
    "We will first see how to get objects from QuPath. As mentionned in the *communicating_with_qupath.ipynb* notebook, there are two ways to communicate with QuPath:\n",
    "- Use one of the functions of `qubalab.qupath.qupath_gateway`.\n",
    "- If no function exists for your use case, use `gateway.entry_point`.\n",
    "\n",
    "In our case, the `qubalab.qupath.qupath_gateway` file has a `get_objects()` function that suits our goal, so we will use it.\n",
    "\n",
    "This function has an `object_type` parameter to define which type of object to retrieve. We will work with annotations here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93b685d-3df9-49d6-a926-210b84994bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qubalab.objects.object_type import ObjectType\n",
    "\n",
    "object_type = ObjectType.ANNOTATION    # could be detection, cell, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680a6939-0fcb-4ee2-bdf5-f805aa7ad71d",
   "metadata": {},
   "source": [
    "### Get annotations as `JavaObject`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdee160d-76e8-4b10-8e5a-abe5e67ec433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello from Python\n",
      "Hello from Python (Other)\n"
     ]
    }
   ],
   "source": [
    "annotations = qupath_gateway.get_objects(object_type = object_type)\n",
    "\n",
    "for annotation in annotations:\n",
    "    print(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b9adea-c292-4967-a7d0-304258435e78",
   "metadata": {},
   "source": [
    "By default, the returned objects are Java objects.\n",
    "\n",
    "This is useful if we want to do something that isn't supported by the `qubalab.qupath.py4j` module, but it isn't very convenient... we end up needing to write Python code that looks a *lot* like Java code. We can also get stuck when things get complicated (e.g. due to threading issues) because we don't have the ability to do *everything* Java can do.\n",
    "\n",
    "We *can* make changes though, like setting names and classifications, which is nice.\n",
    "\n",
    "If we do, we should remember to call `qupath_gateway.refresh_qupath()` to update the interface accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22a3b04-ab34-4bc4-9610-2e10d565d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = annotations[0]\n",
    "\n",
    "# Change the QuPath annotation\n",
    "annotation.setName(\"Hello from Python\")\n",
    "\n",
    "# Refresh the QuPath interface. You should see the changes in QuPath\n",
    "qupath_gateway.refresh_qupath()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bbe83a-8d96-47fe-afcf-6b4f286a0eaf",
   "metadata": {},
   "source": [
    "### Get annotations as `GeoJSON`\n",
    "\n",
    "There's another approach we can take. Rather than directly accessing the QuPath objects, we can request them as GeoJSON. This does *not* give direct access, but rather imports a more Python-friendly representation that is no longer connected to QuPath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7057b24e-035f-408e-b1ad-7b0228d8643d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"geometry\": {\"coordinates\": [[[22161, 7576], [27541, 7576], [27541, 13932], [22161, 13932], [22161, 7576]]], \"plane\": {\"t\": 0, \"z\": 0}, \"type\": \"Polygon\"}, \"id\": \"71d6c4b9-56e8-4922-8552-7a966d869dbf\", \"properties\": {\"color\": [165, 165, 229], \"name\": \"Hello from Python\", \"objectType\": \"annotation\"}, \"type\": \"Feature\"}\n",
      "{\"geometry\": {\"coordinates\": [[[18013, 15255], [18006.97, 15424.47], [17988.9, 15593.27], [17958.87, 15760.74], [17916.99, 15926.21], [17863.43, 16089.04], [17798.4, 16248.57], [17722.15, 16404.18], [17634.99, 16555.25], [17537.27, 16701.2], [17429.36, 16841.43], [17311.69, 16975.41], [17184.73, 17102.59], [17048.98, 17222.49], [16904.97, 17334.62], [16753.27, 17438.54], [16594.49, 17533.84], [16429.24, 17620.15], [16258.18, 17697.13], [16081.99, 17764.47], [15901.36, 17821.9], [15717, 17869.21], [15529.64, 17906.19], [15340.02, 17932.72], [15148.89, 17948.67], [14957, 17954], [14765.11, 17948.67], [14573.98, 17932.72], [14384.36, 17906.19], [14197, 17869.21], [14012.64, 17821.9], [13832.01, 17764.47], [13655.82, 17697.13], [13484.76, 17620.15], [13319.51, 17533.84], [13160.73, 17438.54], [13009.03, 17334.62], [12865.02, 17222.49], [12729.27, 17102.59], [12602.31, 16975.41], [12484.64, 16841.43], [12376.73, 16701.2], [12279.01, 16555.25], [12191.85, 16404.18], [12115.6, 16248.57], [12050.57, 16089.04], [11997.01, 15926.21], [11955.13, 15760.74], [11925.1, 15593.27], [11907.03, 15424.47], [11901, 15255], [11907.03, 15085.53], [11925.1, 14916.73], [11955.13, 14749.26], [11997.01, 14583.79], [12050.57, 14420.96], [12115.6, 14261.43], [12191.85, 14105.82], [12279.01, 13954.75], [12376.73, 13808.8], [12484.64, 13668.57], [12602.31, 13534.59], [12729.27, 13407.41], [12865.02, 13287.51], [13009.03, 13175.38], [13160.73, 13071.46], [13319.51, 12976.16], [13484.76, 12889.85], [13655.82, 12812.87], [13832.01, 12745.53], [14012.64, 12688.1], [14197, 12640.79], [14384.36, 12603.81], [14573.98, 12577.28], [14765.11, 12561.33], [14957, 12556], [15148.89, 12561.33], [15340.02, 12577.28], [15529.64, 12603.81], [15717, 12640.79], [15901.36, 12688.1], [16081.99, 12745.53], [16258.18, 12812.87], [16429.24, 12889.85], [16594.49, 12976.16], [16753.27, 13071.46], [16904.97, 13175.38], [17048.98, 13287.51], [17184.73, 13407.41], [17311.69, 13534.59], [17429.36, 13668.57], [17537.27, 13808.8], [17634.99, 13954.75], [17722.15, 14105.82], [17798.4, 14261.43], [17863.43, 14420.96], [17916.99, 14583.79], [17958.87, 14749.26], [17988.9, 14916.73], [18006.97, 15085.53], [18013, 15255]]], \"isEllipse\": true, \"plane\": {\"t\": 0, \"z\": 0}, \"type\": \"Polygon\"}, \"id\": \"b23d6e95-ca13-4980-b29e-ef3f87db6c0a\", \"properties\": {\"classification\": {\"color\": [255, 200, 0], \"name\": \"Other\"}, \"isLocked\": true, \"name\": \"Hello from Python\", \"objectType\": \"annotation\"}, \"type\": \"Feature\"}\n"
     ]
    }
   ],
   "source": [
    "annotations = qupath_gateway.get_objects(object_type = object_type, converter='geojson')\n",
    "\n",
    "for annotation in annotations:\n",
    "    print(annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03144ae-5060-454e-a910-4864c852b031",
   "metadata": {},
   "source": [
    "In practice, it's really a slightly 'enhanced' GeoJSON representation, because it includes a few extra fields that are relevant for QuPath.\n",
    "\n",
    "This includes any classification, name, color and object type. It also includes a plane, which stores `z` and `t` indices.\n",
    "\n",
    "But because it is still basically GeoJSON, we can use it with other Python libraries that supports GeoJSON... such as `geojson`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c12e15-bac6-4e5f-8cd5-cc5d5fd42343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"Feature\",\n",
      "  \"id\": \"71d6c4b9-56e8-4922-8552-7a966d869dbf\",\n",
      "  \"geometry\": {\n",
      "    \"type\": \"Polygon\",\n",
      "    \"coordinates\": [\n",
      "      [\n",
      "        [\n",
      "          22161,\n",
      "          7576\n",
      "        ],\n",
      "        [\n",
      "          27541,\n",
      "          7576\n",
      "        ],\n",
      "        [\n",
      "          27541,\n",
      "          13932\n",
      "        ],\n",
      "        [\n",
      "          22161,\n",
      "          13932\n",
      "        ],\n",
      "        [\n",
      "          22161,\n",
      "          7576\n",
      "        ]\n",
      "      ]\n",
      "    ],\n",
      "    \"plane\": {\n",
      "      \"z\": 0,\n",
      "      \"t\": 0\n",
      "    }\n",
      "  },\n",
      "  \"properties\": {\n",
      "    \"name\": \"Hello from Python\",\n",
      "    \"color\": [\n",
      "      165,\n",
      "      165,\n",
      "      229\n",
      "    ],\n",
      "    \"objectType\": \"annotation\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import geojson\n",
    "\n",
    "print(geojson.dumps(annotations[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c483aa-c92d-485f-9aef-ba293a76f897",
   "metadata": {},
   "source": [
    "We can also use it with `Shapely`, which is particularly useful.\n",
    "\n",
    "Shapely gives us access to lots of useful methods - and shapely objects can be displayed nicely in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "647cfa9d-e816-4204-9db5-c1cdf1bc2ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"300\" height=\"300\" viewBox=\"21906.76 7321.76 5888.480000000003 6864.48\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,21508.0)\"><path fill-rule=\"evenodd\" fill=\"#66cc99\" stroke=\"#555555\" stroke-width=\"45.7632\" opacity=\"0.6\" d=\"M 22161.0,7576.0 L 27541.0,7576.0 L 27541.0,13932.0 L 22161.0,13932.0 L 22161.0,7576.0 z\" /></g></svg>"
      ],
      "text/plain": [
       "<POLYGON ((22161 7576, 27541 7576, 27541 13932, 22161 13932, 22161 7576))>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shapely.geometry import shape\n",
    "\n",
    "shape(annotations[0].geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a349d3-127b-4e69-87d8-e47c762b74e0",
   "metadata": {},
   "source": [
    "## Add and remove objects from QuPath\n",
    "\n",
    "The GeoJSON representation doesn't give us direct access to the QuPath objects, but we can still make changes and send them back.\n",
    "\n",
    "The easiest way to see this in action is to begin by deleting the annotations and then adding them back again - but this time with a different color.\n",
    "\n",
    "> We only assign colors to annotations that aren't classified, so that we don't override the colors that QuPath uses for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c166ae-63a7-4fc2-afeb-c32ab65226ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for annotation in annotations:\n",
    "    if not annotation.classification:\n",
    "        annotation.color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "qupath_gateway.delete_objects(object_type = object_type)\n",
    "qupath_gateway.add_objects(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a0faa-29b4-4f8b-9df3-c038d060cabc",
   "metadata": {},
   "source": [
    "## Create masks & labeled images\n",
    "\n",
    "One reason to use Python rather than QuPath/Java is that NumPy/SciPy/scikit-image and other tools make working with pixels easier and more fun.\n",
    "\n",
    "To begin, let's use the GeoJSON representation to create masks and labeled images.\n",
    "\n",
    "To create masks and labeled images, Qubalab has a `LabeledImageServer` class. This class is an implementation of the qubalab `ImageServer` which is described in the *opening_images.ipynb* notebook, so it is recommended that you go through this notebook first.\n",
    "\n",
    "This server needs:\n",
    "- Some metadata representing the image containing the objects. Since we are working with the image that is opened in QuPath, we can the metadata of the `QuPathServer`, as described in *communicating_with_qupath.ipynb*.\n",
    "- The objects to represent. We will give the annotations we've been working with.\n",
    "- A downsample to apply to the image.\n",
    "\n",
    "Once the server is created, all functions described in *opening_images.ipynb* (such as `read_region()` to read the image) are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0caec8f-f900-4e37-bf0e-06c8bb28ad0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from qubalab.images.qupath_server import QuPathServer\n",
    "from qubalab.images.labeled_server import LabeledImageServer\n",
    "\n",
    "metadata = QuPathServer(gateway).metadata\n",
    "downsample = 20\n",
    "\n",
    "labeled_server = LabeledImageServer(metadata, annotations, downsample=downsample)\n",
    "label_image = labeled_server.read_region()\n",
    "\n",
    "# This calls a utility function from qubalab to plot the image\n",
    "from qubalab.display.plot import plotImage\n",
    "plotImage(label_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57ccb3-a06f-4c43-92e9-fb864721008c",
   "metadata": {},
   "source": [
    "By default, the `LabeledImageServer` will return a single channel image where all objects are represented by integer values (labels). It's a labeled image.\n",
    "\n",
    "Another option is to create a multi channel image where each channel is a mask indicating if an annotation is present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5585d2c5-95ca-49ce-91fe-e87d5777dcae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask_server = LabeledImageServer(metadata, annotations, downsample=downsample, multichannel=True)\n",
    "\n",
    "masks = mask_server.read_region()\n",
    "\n",
    "# masks contains (n+1) channels, where n is the number of annotations\n",
    "# The i channel corresponds to the mask representing the i annotation\n",
    "# Let's plot the first mask\n",
    "plotImage(masks, channel=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc04203-6ef1-41df-8a70-2ea1d5782a54",
   "metadata": {},
   "source": [
    "## Image processing & creating objects\n",
    "\n",
    "This whole thing becomes more useful when we start to use Python for image processing.\n",
    "\n",
    "Here we'll use scikit-image to help find objects using two different thresholding methods. We'll then convert them to QuPath objects and add them to the current QuPath viewer for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9f415-8100-4e79-b459-1c1cebc0afd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
